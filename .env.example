# Climate Funding Intel â€” Pipeline Environment Variables (example)
# Copy this file to pipeline/.env for local development and fill in the values.
# Never commit real secrets.

# Supabase (Service Role used only by the pipeline)
SUPABASE_URL=""
SUPABASE_SERVICE_ROLE_KEY=""
SUPABASE_TABLE="funding_events"
## Optional: Sandbox table for integration testing (used only by integration tests)
SUPABASE_TABLE_SANDBOX=""

# Tavily (Search)
TAVILY_API_KEY=""

# Google Gemini (LLM)
# Get a key from https://aistudio.google.com/apikey
GEMINI_API_KEY=""
# Default model id, see https://docs.crewai.com/en/concepts/llms
MODEL="gemini-2.0-flash"
# Optional comma-separated list of fallback models to try if the primary hits
# per-model rate limits or transient errors. Examples:
#   LLM_MODEL_FALLBACKS="gemini-1.5-flash,gemini-1.5-pro"
#   LLM_MODEL_FALLBACKS="gemini-2.0-flash-lite,gemini-1.5-flash"
LLM_MODEL_FALLBACKS=""

# Optional LLM tuning
LLM_TEMPERATURE="0.2"
LLM_TIMEOUT="120"
LLM_MAX_TOKENS="4000"
LLM_SEED="42"

# Optional: Logging level for the pipeline (INFO, DEBUG)
LOG_LEVEL="INFO"

# Optional: LLM retry/backoff for rate limits (used by pipeline/main.py)
# Number of retries when transient/rate limit errors occur
LLM_MAX_RETRIES="3"
# Base delay in seconds for exponential backoff (30, then 60, 120, ...)
LLM_RETRY_BASE_DELAY="30"
